{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenyi/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: read_table is deprecated, use read_csv instead.\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "path = os.path.abspath('..')\n",
    "data_path = os.path.join(path, 'data', 'adult.data')\n",
    "names = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation',\n",
    "         'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country', 'target']\n",
    "data = pd.read_table(data_path, sep=',', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass  fnlwgt   education  education-num  \\\n",
       "0   39          State-gov   77516   Bachelors             13   \n",
       "1   50   Self-emp-not-inc   83311   Bachelors             13   \n",
       "2   38            Private  215646     HS-grad              9   \n",
       "3   53            Private  234721        11th              7   \n",
       "4   28            Private  338409   Bachelors             13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week  native-country  target  \n",
       "0          2174             0              40   United-States   <=50K  \n",
       "1             0             0              13   United-States   <=50K  \n",
       "2             0             0              40   United-States   <=50K  \n",
       "3             0             0              40   United-States   <=50K  \n",
       "4             0             0              40            Cuba   <=50K  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 特征工程\n",
    "# target\n",
    "data['target'] = data['target'].apply(lambda x: 0 if x == ' <=50K' else 1)\n",
    "# age\n",
    "bins = [-np.inf,18, 25, 35, 45, 50, np.inf]\n",
    "labels = list(range(len(bins)-1))\n",
    "data['age'] = pd.cut(data['age'], bins=bins, labels=labels)\n",
    "\n",
    "# education-num\n",
    "bins = [-np.inf, 5, 10, 20, 40, np.inf]\n",
    "labels = list(range(len(bins)-1))\n",
    "data['education-num'] = pd.cut(data['education-num'], bins=bins, labels=labels)\n",
    "\n",
    "\n",
    "# hours-per-week\n",
    "bins = [-np.inf, 10, 30, 40, 70, np.inf]\n",
    "labels = list(range(len(bins)-1))\n",
    "data['hours-per-week'] = pd.cut(data['hours-per-week'], bins=bins, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wenyi/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/wenyi/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/wenyi/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "continuous_cols = ['fnlwgt', 'capital-gain', 'capital-loss']\n",
    "cat_columns = [col for col in data.columns if col not in continuous_cols+['age', 'hours-per-week', 'education-num']]\n",
    "# deep_columns = ['workclass','fnlwgt', 'education', 'marital-status', 'occupation', 'relationship', 'race', \n",
    "#                 'native-country']\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "for col in cat_columns:\n",
    "    le = LabelEncoder()\n",
    "    data[col] = le.fit_transform(data[col])\n",
    "    \n",
    "for col in continuous_cols:\n",
    "    mms = MinMaxScaler()\n",
    "    data[col] = mms.fit_transform(data[col].values.reshape(-1,1)).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>0.044302</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02174</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.048238</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0.138113</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.151068</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.221488</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  age  workclass    fnlwgt  education education-num  marital-status  \\\n",
       "0   3          7  0.044302          9             2               4   \n",
       "1   4          6  0.048238          9             2               2   \n",
       "2   3          4  0.138113         11             1               0   \n",
       "3   5          4  0.151068          1             1               2   \n",
       "4   2          4  0.221488          9             2               2   \n",
       "\n",
       "   occupation  relationship  race  sex  capital-gain  capital-loss  \\\n",
       "0           1             1     4    1       0.02174           0.0   \n",
       "1           4             0     4    1       0.00000           0.0   \n",
       "2           6             1     4    1       0.00000           0.0   \n",
       "3           6             0     2    1       0.00000           0.0   \n",
       "4          10             5     2    0       0.00000           0.0   \n",
       "\n",
       "  hours-per-week  native-country  target  \n",
       "0              2              39       0  \n",
       "1              1              39       0  \n",
       "2              2              39       0  \n",
       "3              2              39       0  \n",
       "4              2               5       0  "
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num',\n",
       "       'marital-status', 'occupation', 'relationship', 'race', 'sex',\n",
       "       'capital-gain', 'capital-loss', 'hours-per-week', 'native-country',\n",
       "       'target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse and cross feature\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "wide_columns = ['age','workclass', 'education', 'education-num','occupation', 'relationship', \n",
    "                'hours-per-week','native-country', 'marital-status', 'sex']\n",
    "data_wide = data[wide_columns]\n",
    "cross_columns = [['occupation', 'sex'], ['occupation', 'education'], ['education', 'native-country'],\n",
    "                 ['age', 'occupation'], ['age', 'hours-per-week'], ['sex', 'education']]\n",
    "for l in cross_columns:\n",
    "    poly = PolynomialFeatures()\n",
    "    c = poly.fit_transform(data_wide[l])\n",
    "    c = pd.DataFrame(c, columns=[l[0]+'_'+l[1]+'_{}'.format(i) for i in range(c.shape[1])])\n",
    "    data_wide = pd.concat((data_wide, c), axis=1)\n",
    "\n",
    "# onehot\n",
    "for col in wide_columns:\n",
    "    data_wide[col] = data_wide[col].astype('str')\n",
    "data_wide = pd.get_dummies(data_wide)\n",
    "data_target = data['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 构建embedding dict\n",
    "deep_columns = ['workclass', 'occupation', 'native-country', 'race', 'fnlwgt', 'capital-gain', 'capital-loss']\n",
    "data_deep = data[deep_columns]\n",
    "embedding_columns = ['workclass', 'occupation', 'native-country', 'race']\n",
    "embedding_columns_dict = {}\n",
    "for i in range(len(deep_columns)):\n",
    "    if deep_columns[i] in embedding_columns:\n",
    "        col_name = deep_columns[i]\n",
    "        embedding_columns_dict[col_name] = (len(data_deep[col_name].unique()), 8)\n",
    "deep_columns_idx = dict()\n",
    "for idx, key in enumerate(data_deep.columns):\n",
    "    deep_columns_idx[key] = idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_wide, test_wide = train_test_split(data_wide, test_size=0.4, random_state=999)\n",
    "train_deep, test_deep = train_test_split(data_deep, test_size=0.4, random_state=999)\n",
    "train_target, test_target = train_test_split(data_target, test_size=0.4, random_state=999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import  torch.nn.functional as F\n",
    "\n",
    "def linear(inp, out, dropout):\n",
    "    return nn.Sequential(\n",
    "        nn.Linear(inp, out),\n",
    "        nn.LeakyReLU(),\n",
    "        nn.Dropout(dropout)\n",
    "    )\n",
    "\n",
    "class DeepModel(nn.Module):\n",
    "    def __init__(self, deep_columns_idx, embedding_columns_dict, hidden_layers, dropouts, output_dim):\n",
    "        \"\"\"\n",
    "        :param deep_columns_dict: dict include categories columns name and number of unique val and \n",
    "                                embedding dimension  e.g. {'age':(10, 32)}\n",
    "        :param hidden_layers: number of hidden layers\n",
    "        :param deep_columns_idx: dict of columns name and columns index\n",
    "        :param dropout: list of float each hidden layers dropout len(dropouts) == hidden_layers - 1\n",
    "        \"\"\"\n",
    "        super(DeepModel, self).__init__()\n",
    "        self.embedding_columns_dict = embedding_columns_dict\n",
    "        self.deep_columns_idx = deep_columns_idx\n",
    "        for key, val in embedding_columns_dict.items():\n",
    "            setattr(self, 'dense_col_'+key, nn.Embedding(val[0], val[1]))\n",
    "        embedding_layer = 0\n",
    "        for col in self.deep_columns_idx.keys():\n",
    "            if col in embedding_columns_dict:\n",
    "                embedding_layer += embedding_columns_dict[col][1]\n",
    "            else:\n",
    "                embedding_layer += 1\n",
    "        self.layers = nn.Sequential()\n",
    "        hidden_layers = [embedding_layer] + hidden_layers\n",
    "        dropouts = [0.0] + dropouts\n",
    "        for i in range(1, len(hidden_layers)):\n",
    "            self.layers.add_module(\n",
    "                'hidden_layer_{}'.format(i-1),\n",
    "                linear(hidden_layers[i-1], hidden_layers[i], dropouts[i-1])\n",
    "            )\n",
    "        self.layers.add_module('last_linear', nn.Linear(hidden_layers[-1], output_dim))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        emb = []\n",
    "        continuous_cols = [col for col in self.deep_columns_idx.keys() if col not in self.embedding_columns_dict]\n",
    "        for col, _ in self.embedding_columns_dict.items():\n",
    "            if col not in self.deep_columns_idx:\n",
    "                raise ValueError(\"ERROR column name may be your deep_columns_idx dict is not math the\"\n",
    "                                 \"embedding_columns_dict\")\n",
    "            else:\n",
    "                idx = self.deep_columns_idx[col]\n",
    "                emb.append(getattr(self, 'dense_col_'+col)(x[:, idx].long()))\n",
    "\n",
    "        for col in continuous_cols:\n",
    "            idx = self.deep_columns_idx[col]\n",
    "            emb.append(x[:, idx].view(-1, 1))\n",
    "        embedding_layers = torch.cat(emb, dim=1)\n",
    "        out = self.layers(embedding_layers)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideModel(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, dropout=0):\n",
    "        \"\"\"\n",
    "        wide model using LR\n",
    "        :param input_dim: int the dimension of wide model input\n",
    "        :param output_dim: int the dimension of wide model output\n",
    "        \"\"\"\n",
    "        super(WideModel, self).__init__()\n",
    "        self.linear = linear(input_dim, output_dim, dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WideDeep(nn.Module):\n",
    "    def __init__(self, wide_model_params,\n",
    "                 deep_model_params, activation):\n",
    "        \"\"\"\n",
    "        wide deep model\n",
    "        :param wide_columns_idx:\n",
    "        :param deep_columns_idx:\n",
    "        :param activation:\n",
    "        \"\"\"\n",
    "        super(WideDeep, self).__init__()\n",
    "        self.activation = self.set_activation(activation)\n",
    "#         self.wide_model_params = wide_model_params\n",
    "#         self.deep_model_params = deep_model_params\n",
    "        \n",
    "        # wide model parameters\n",
    "        wide_input_dim = wide_model_params['wide_input_dim']\n",
    "        wide_output_dim = wide_model_params['wide_output_dim']\n",
    "        self.wide = WideModel(wide_input_dim, wide_output_dim)\n",
    "        \n",
    "        # deep model parameters\n",
    "        deep_columns_idx = deep_model_params['deep_columns_idx']\n",
    "        embedding_columns_dict = deep_model_params['embedding_columns_dict']\n",
    "        hidden_layers = deep_model_params['hidden_layers']\n",
    "        dropouts = deep_model_params['dropouts']\n",
    "        deep_output_dim = deep_model_params['deep_output_dim']\n",
    "        self.deep = DeepModel(deep_columns_idx=deep_columns_idx,\n",
    "                         embedding_columns_dict=embedding_columns_dict,\n",
    "                         hidden_layers=hidden_layers,\n",
    "                         dropouts=dropouts,\n",
    "                         output_dim=deep_output_dim)\n",
    "#         self.param = {'wide':self.wide.parameters(), 'deep':self.deep.parameters()}\n",
    "\n",
    "    def set_activation(self, activation):\n",
    "        assert activation in [None, 'sigmoid', 'softmax']\n",
    "        if activation == 'sigmoid':     # for binary classification\n",
    "            return F.sigmoid\n",
    "        elif activation == 'softmax':   # for multiple classification\n",
    "            return F.softmax\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        input and forward\n",
    "        :param x: tuple(wide_model_data, deep_model_data)\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # wide model\n",
    "        wide_data = x[0]\n",
    "        wide_out = self.wide(wide_data)\n",
    "\n",
    "        # deep model\n",
    "        deep_data = x[1]\n",
    "        deep_out = self.deep(deep_data)\n",
    "\n",
    "        assert wide_out.size() == deep_out.size()\n",
    "        wide_deep = wide_out.add(deep_out)\n",
    "        if not self.activation:\n",
    "            return wide_deep\n",
    "        elif self.activation == F.softmax:\n",
    "            out = self.activation(wide_deep, dim=1)\n",
    "        else:\n",
    "            out = self.activation(wide_deep)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "def valid_epoch(model, valid_loader, epoch):\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    targets = []\n",
    "    outs = []\n",
    "    for idx, (data_wide, data_deep, target) in enumerate(valid_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "        x = (data_wide, data_deep)\n",
    "        out = model(x)\n",
    "        loss = criterion(target, out)\n",
    "        losses.append(loss.item())\n",
    "        targets += list(target.numpy())\n",
    "        out = out.view(-1).detach().numpy()\n",
    "        outs += list(np.int64(out>0.5))\n",
    "    met = accuracy_score(targets, outs)\n",
    "    return met, sum(losses)/len(losses)\n",
    "\n",
    "\n",
    "def train_epoch(model, train_loader, test_loader,optimizer, epoch, validation=True):\n",
    "    model.train()\n",
    "    for idx, (data_wide, data_deep, target) in enumerate(train_loader):\n",
    "#         data_wide, data_deep, target = data.to(device), target.to(device)\n",
    "        x = (data_wide, data_deep)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "        loss = criterion(target, out)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (idx+1) % 400 == 0:\n",
    "            print(\"Epoch %d iteration %d loss is %.4f\" %(epoch+1, idx+1, loss.item()))\n",
    "        if idx == len(train_loader):\n",
    "            break\n",
    "    \n",
    "    if validation:\n",
    "        met, loss = valid_epoch(model, test_loader, epoch)\n",
    "        print(\"Epoch %d validation loss is %.4f and validation metrics is %.4f\" %(epoch, loss, met))\n",
    "\n",
    "\n",
    "def train(model, train_loader, test_loader, epochs, optimzers, validation):\n",
    "    for epoch in range(epochs):\n",
    "        train_epoch(model, train_loader, test_loader,optimzers, epoch, validation)\n",
    "\n",
    "        \n",
    "# save model的问题，保存整个模型及参数，如果模型很大加载的时候会很慢，不适用与在线预测，在线预测一般是只将模型参数保存及model.state_dict\n",
    "# 如果实现的是模型的继续训练，则需要同时保存优化器和当前训练的epoch，不保存epoch的话每次训练依然是从第epoch=0开始训练\n",
    "# 在线预测的时候需要现定义好网络结构，然后load网络参数进行预测即可\n",
    "def save_model(model, path):\n",
    "    torch.save(model.state_dict(), path)\n",
    "\n",
    "# 参数model是事先定义好的网络模型\n",
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "class trainset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.wide_data = data[0]\n",
    "        self.deep_data = data[1]\n",
    "        self.target = data[2]\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        wide_data = self.wide_data[index]\n",
    "        deep_data = self.deep_data[index]\n",
    "        target = self.target[index]\n",
    "        return (wide_data, deep_data, target)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultipleOptimizer():\n",
    "    def __init__(self, opts):\n",
    "        self.optimizers = opts\n",
    "        \n",
    "    def zero_grad(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.zero_grad()\n",
    "            \n",
    "    def step(self):\n",
    "        for opt in self.optimizers:\n",
    "            opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = (torch.Tensor(train_wide.values), torch.Tensor(train_deep.values), torch.Tensor(train_target.values))\n",
    "train_data = trainset(x)\n",
    "x1 = (torch.Tensor(test_wide.values), torch.Tensor(test_deep.values), torch.Tensor(test_target.values))\n",
    "test_data = trainset(x1)\n",
    "trainloader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "testloader = DataLoader(test_data, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_model_params = {\n",
    "    'deep_columns_idx': deep_columns_idx,\n",
    "    'embedding_columns_dict': embedding_columns_dict, \n",
    "    'hidden_layers':[64, 32, 16],\n",
    "    'dropouts':[0.5, 0.5],\n",
    "    'deep_output_dim':1}\n",
    "wide_model_params = {\n",
    "    'wide_input_dim':data_wide.shape[1],\n",
    "    'wide_output_dim':1\n",
    "}\n",
    "activation = 'sigmoid'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "widedeep = WideDeep(wide_model_params, deep_model_params, activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "def criterion(target, out):\n",
    "    return F.binary_cross_entropy(out, target.view(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 iteration 400 loss is 0.5278\n",
      "Epoch 0 validation loss is 0.3735 and validation metrics is 0.8210\n",
      "Epoch 2 iteration 400 loss is 0.4419\n",
      "Epoch 1 validation loss is 0.3707 and validation metrics is 0.8369\n",
      "Epoch 3 iteration 400 loss is 0.5276\n",
      "Epoch 2 validation loss is 0.3675 and validation metrics is 0.8383\n",
      "Epoch 4 iteration 400 loss is 0.3358\n",
      "Epoch 3 validation loss is 0.3595 and validation metrics is 0.8364\n",
      "Epoch 5 iteration 400 loss is 0.3180\n",
      "Epoch 4 validation loss is 0.3474 and validation metrics is 0.8447\n",
      "Epoch 6 iteration 400 loss is 0.3447\n",
      "Epoch 5 validation loss is 0.3497 and validation metrics is 0.8428\n",
      "Epoch 7 iteration 400 loss is 0.2919\n",
      "Epoch 6 validation loss is 0.3510 and validation metrics is 0.8385\n",
      "Epoch 8 iteration 400 loss is 0.3935\n",
      "Epoch 7 validation loss is 0.3489 and validation metrics is 0.8431\n",
      "Epoch 9 iteration 400 loss is 0.2405\n",
      "Epoch 8 validation loss is 0.3497 and validation metrics is 0.8479\n",
      "Epoch 10 iteration 400 loss is 0.2913\n",
      "Epoch 9 validation loss is 0.3397 and validation metrics is 0.8438\n",
      "Epoch 11 iteration 400 loss is 0.3998\n",
      "Epoch 10 validation loss is 0.3402 and validation metrics is 0.8430\n",
      "Epoch 12 iteration 400 loss is 0.3814\n",
      "Epoch 11 validation loss is 0.3485 and validation metrics is 0.8445\n",
      "Epoch 13 iteration 400 loss is 0.2956\n",
      "Epoch 12 validation loss is 0.3371 and validation metrics is 0.8477\n",
      "Epoch 14 iteration 400 loss is 0.3589\n",
      "Epoch 13 validation loss is 0.3375 and validation metrics is 0.8478\n",
      "Epoch 15 iteration 400 loss is 0.3206\n",
      "Epoch 14 validation loss is 0.3357 and validation metrics is 0.8456\n",
      "Epoch 16 iteration 400 loss is 0.3433\n",
      "Epoch 15 validation loss is 0.3543 and validation metrics is 0.8453\n",
      "Epoch 17 iteration 400 loss is 0.3082\n",
      "Epoch 16 validation loss is 0.3402 and validation metrics is 0.8471\n",
      "Epoch 18 iteration 400 loss is 0.3562\n",
      "Epoch 17 validation loss is 0.3340 and validation metrics is 0.8506\n",
      "Epoch 19 iteration 400 loss is 0.2889\n",
      "Epoch 18 validation loss is 0.3387 and validation metrics is 0.8443\n",
      "Epoch 20 iteration 400 loss is 0.4522\n",
      "Epoch 19 validation loss is 0.3349 and validation metrics is 0.8445\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.Adam(widedeep.parameters(), lr = 0.01)\n",
    "train(widedeep,  trainloader, testloader,20, optimizer, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([    7,     8,     9, ..., 32554, 32557, 32560]),)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(data['target'].values==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' White', ' Black', ' Asian-Pac-Islander', ' Amer-Indian-Eskimo',\n",
       "       ' Other'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# race\n",
    "data['race'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Not-in-family', ' Husband', ' Wife', ' Own-child', ' Unmarried',\n",
       "       ' Other-relative'], dtype=object)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relationship\n",
    "data['relationship'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([' Male', ' Female'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sex\n",
    "data['sex'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
